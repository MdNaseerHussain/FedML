{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated ML\n",
    "## Contents\n",
    "1. Introduction\n",
    "1. Reading an image from the dataset\n",
    "1. Loading Images and Labels\n",
    "1. Splitting training and testing data\n",
    "1. Creating clients\n",
    "1. Creating helper nodes\n",
    "1. Batching clients' and test data\n",
    "1. Creating an MLP model\n",
    "1. Optimizer, Loss function and Metrics to compile the model\n",
    "1. Utility functions for the Federated Averaging\n",
    "1. Functions to fetch and set shape of model weights\n",
    "1. Modulation and Demodulation functions for Communication\n",
    "1. Transmission functions from Client to Helper and Helper to Master\n",
    "1. Model test function\n",
    "1. Federated Averaging Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we have implemented i working Federated ML model. The goal is to simulate packet losses in communication between the server and the clients in the Federated Averaging Algorithm. The function once implemented will be added to the algorithm near the TODO's in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "image = cv2.imread(\"datasets/numbers/trainingSet/0/img_1.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.title(\"Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processed 1/10\n",
      "[INFO] Processed 2/10\n",
      "[INFO] Processed 3/10\n",
      "[INFO] Processed 4/10\n",
      "[INFO] Processed 5/10\n",
      "[INFO] Processed 6/10\n",
      "[INFO] Processed 7/10\n",
      "[INFO] Processed 8/10\n",
      "[INFO] Processed 9/10\n",
      "[INFO] Processed 10/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dir_path = \"datasets/numbers/trainingSet/\"\n",
    "images = list()\n",
    "labels = list()\n",
    "for number in range(0, 10):\n",
    "    folder = dir_path + str(number)\n",
    "    for image_file in os.listdir(folder):\n",
    "        image_gray = cv2.imread(os.path.join(folder, image_file), cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.array(image_gray).flatten()\n",
    "        images.append(image/255)\n",
    "        labels.append(number)\n",
    "    print(\"[INFO] Processed {}/{}\".format(number + 1, 10))\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num_clients = 16\n",
    "client_names = [\"client_{}\".format(i + 1) for i in range(num_clients)]\n",
    "data = list(zip(images, labels))\n",
    "random.shuffle(data)\n",
    "size = len(data)//num_clients\n",
    "data_shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "clients = {client_names[i]: data_shards[i] for i in range(num_clients)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating helper nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "num_helpers = math.ceil(math.log2(num_clients))\n",
    "error_links = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching clients' and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "batch_size = 32\n",
    "clients_batched = dict()\n",
    "for (client_name, data_shard) in clients.items():\n",
    "    data, labels = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(labels)))\n",
    "    clients_batched[client_name] = dataset.shuffle(len(labels)).batch(batch_size)\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((images_test, labels_test)).batch(len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Multi Layer Perception (MLP) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_shape=(shape,)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, Loss function and Metrics to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdnaj\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "lr = 0.01 \n",
    "comms_round = 100\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = SGD(lr=lr, decay=lr/comms_round, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions for the Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_scaling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    avg_grad = list()\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to fetch and set shape of model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(weights):\n",
    "    shapes = [i.shape for i in weights]\n",
    "    return shapes\n",
    "\n",
    "def flatten_model_weights(weights):\n",
    "    flattened_weights = np.concatenate([i.flatten() for i in weights])\n",
    "    return flattened_weights\n",
    "\n",
    "def restore_model_shape(flattened_weights, shapes):\n",
    "    weights = []\n",
    "    index = 0\n",
    "    for shape in shapes:\n",
    "        size = np.product(shape)\n",
    "        arr = np.array(flattened_weights[index : index + size])\n",
    "        weights.append(arr.reshape(shape))\n",
    "        index += size\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modulation and Demodulation Functions for Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import random\n",
    "\n",
    "def modulation(weights):\n",
    "    weights = flatten_model_weights(weights)\n",
    "    packets = []\n",
    "    for i in range(len(weights)):\n",
    "        packet = BitArray(float=weights[i], length=32)\n",
    "        packets.append(packet.bin)\n",
    "    return packets\n",
    "\n",
    "def demodulation(weights, model_shape):\n",
    "    return restore_model_shape(weights, model_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transmission functions from Client to Helper and Helper to Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_weights_list = []\n",
    "comm_matrix = []\n",
    "\n",
    "def masterReceiver(helpersData):\n",
    "    g1 = helpersData[0]\n",
    "    g2 = helpersData[1]\n",
    "    g3 = helpersData[2]\n",
    "    g4 = helpersData[3]\n",
    "    if g1 == 'X':\n",
    "        g1 = [0]*len(g2)\n",
    "        for i in range(len(g2)):\n",
    "            g1[i] = g4[i] - g2[i] - g3[i]\n",
    "    if g2 == 'X':\n",
    "        g2 = [0]*len(g1)\n",
    "        for i in range(len(g1)):\n",
    "            g2[i] = g4[i] - g1[i] - g3[i]\n",
    "    if g3 == 'X':\n",
    "        g3 = [0]*len(g4)\n",
    "        for i in range(len(g4)):\n",
    "            if i < len(g1):\n",
    "                g3[i] = g4[i] - g1[i] - g2[i]\n",
    "            else:\n",
    "                g3[i] = g4[i]\n",
    "    g = g1 + g2 + g3    \n",
    "    scaled_weights_list.append(g)\n",
    "\n",
    "def create_comm_matrix(num_clients, num_helpers):\n",
    "    scaled_weights_list.clear()\n",
    "    comm_matrix.clear()\n",
    "    for i in range(num_clients):\n",
    "        comm_matrix.append([])\n",
    "        for j in range(num_helpers):\n",
    "            comm_matrix[i].append(0)\n",
    "            comm_matrix[i][j] = 'XX'\n",
    "    return comm_matrix\n",
    "\n",
    "def transmissionCH(bitWeights, comm_matrix, client, packet_loss_prob):\n",
    "    g1 = bitWeights[:len(bitWeights)//3]\n",
    "    g2 = bitWeights[len(bitWeights)//3:2*len(bitWeights)//3]\n",
    "    g3 = bitWeights[2*len(bitWeights)//3:]\n",
    "    g4 = []\n",
    "    for i in range(len(g3)):\n",
    "        w1 = 0\n",
    "        if i < len(g1):\n",
    "            w1 = BitArray(bin=g1[i]).float\n",
    "        w2 = 0\n",
    "        if i < len(g2):\n",
    "            w2 = BitArray(bin=g2[i]).float\n",
    "        w3 = BitArray(bin=g3[i]).float\n",
    "        w4 = w1 + w2 + w3\n",
    "        g4.append(BitArray(float=w4, length=32).bin)\n",
    "    g1 = ''.join(g1)\n",
    "    g2 = ''.join(g2)\n",
    "    g3 = ''.join(g3)\n",
    "    g4 = ''.join(g4)\n",
    "    comm_matrix[client][0] = g1\n",
    "    comm_matrix[client][1] = g2\n",
    "    comm_matrix[client][2] = g3\n",
    "    comm_matrix[client][3] = g4\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][0] = 'X'*len(g1)\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][1] = 'X'*len(g2)\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][2] = 'X'*len(g3)\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][3] = 'X'*len(g4)\n",
    "\n",
    "def transmissionHM(comm_matrix):\n",
    "    comm_links = {}\n",
    "    lost_clients = 0\n",
    "    for i in range(len(comm_matrix)):\n",
    "        mask = ''\n",
    "        for j in range(len(comm_matrix[i])):\n",
    "            if comm_matrix[i][j][0] != 'X':\n",
    "                mask += '1'\n",
    "            else:\n",
    "                mask += '0'\n",
    "        if mask in comm_links:\n",
    "            comm_links[mask].append(i)\n",
    "        else:\n",
    "            comm_links[mask] = [i]\n",
    "    for mask in comm_links:\n",
    "        summed_g1 = [0]*(len(comm_matrix[0][0])//32)\n",
    "        summed_g2 = [0]*(len(comm_matrix[0][1])//32)\n",
    "        summed_g3 = [0]*(len(comm_matrix[0][2])//32)\n",
    "        summed_g4 = [0]*(len(comm_matrix[0][3])//32)\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i] == '1':\n",
    "                for client in comm_links[mask]:\n",
    "                    if i == 0:\n",
    "                        g1 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g1[j//32] = BitArray(bin=comm_matrix[client][i][j:j+32]).float\n",
    "                        for j in range(len(g1)):\n",
    "                            summed_g1[j] += g1[j]\n",
    "                    elif i == 1:\n",
    "                        g2 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g2[j//32] = BitArray(bin=comm_matrix[client][i][j: j+32]).float\n",
    "                        for j in range(len(g2)):\n",
    "                            summed_g2[j] += g2[j]\n",
    "                    elif i == 2:\n",
    "                        g3 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g3[j//32] = BitArray(bin=comm_matrix[client][i][j: j+32]).float\n",
    "                        for j in range(len(g3)):\n",
    "                            summed_g3[j] += g3[j]\n",
    "                    else:\n",
    "                        g4 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g4[j//32] = BitArray(bin=comm_matrix[client][i][j: j+32]).float\n",
    "                        for j in range(len(g4)):\n",
    "                            summed_g4[j] += g4[j]\n",
    "        X_cnt = 0\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i] == '0':\n",
    "                X_cnt += 1\n",
    "                if i == 0:\n",
    "                    summed_g1 = 'X'\n",
    "                elif i == 1:\n",
    "                    summed_g2 = 'X'\n",
    "                elif i == 2:\n",
    "                    summed_g3 = 'X'\n",
    "                else:\n",
    "                    summed_g4 = 'X'\n",
    "        if X_cnt > 1:\n",
    "            lost_clients += len(comm_links[mask])\n",
    "        else:\n",
    "            masterReceiver([summed_g1, summed_g2, summed_g3, summed_g4])\n",
    "    return [scaled_weights_list, lost_clients]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import CategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = CategoricalCrossentropy(from_logits=True)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round+1, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated Averaging Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def fedML(packet_loss_prob=0):\n",
    "    smlp_global = SimpleMLP()\n",
    "    global_model = smlp_global.build(784, 10)\n",
    "    model_shape = get_shape(global_model.get_weights())\n",
    "    accuracy = []\n",
    "    for comm_round in range(comms_round):\n",
    "        global_weights = global_model.get_weights()\n",
    "        client_names= list(clients_batched.keys())\n",
    "        comm_matrix = create_comm_matrix(num_clients, num_helpers)\n",
    "        random.shuffle(client_names)\n",
    "        for client_number, client in enumerate(client_names):\n",
    "            smlp_local = SimpleMLP()\n",
    "            local_model = smlp_local.build(784, 10)\n",
    "            local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "            local_model.set_weights(global_weights)\n",
    "            local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "            scaling_factor = weight_scaling_factor(clients_batched, client)\n",
    "            scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "            bitWeights = modulation(scaled_weights)\n",
    "            transmissionCH(bitWeights, comm_matrix, client_number, packet_loss_prob)\n",
    "            K.clear_session()\n",
    "        scaled_weights_list, lost_clients = transmissionHM(comm_matrix)\n",
    "        if lost_clients != 0:\n",
    "            compensated_lost_weights = scale_model_weights(global_weights, lost_clients*weight_scaling_factor(clients_batched, 'client_1'))\n",
    "            packets = modulation(compensated_lost_weights)\n",
    "            weights = packets\n",
    "            for i in range(len(packets)):\n",
    "                weights[i] = BitArray(bin=packets[i]).float\n",
    "            scaled_weights_list.append(weights)\n",
    "        global_weights = sum_scaled_weights(scaled_weights_list)\n",
    "        global_weights = demodulation(global_weights, model_shape)\n",
    "        global_model.set_weights(global_weights)\n",
    "        for(X_test, Y_test) in test_batched:\n",
    "            global_acc, _ = test_model(X_test, Y_test, global_model, comm_round)\n",
    "            accuracy.append(global_acc)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 4ms/step\n",
      "comm_round: 1 | global_acc: 85.667% | global_loss: 1.8777011632919312\n",
      "132/132 [==============================] - 1s 4ms/step\n",
      "comm_round: 2 | global_acc: 88.643% | global_loss: 1.7394077777862549\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 3 | global_acc: 89.619% | global_loss: 1.6635996103286743\n",
      "132/132 [==============================] - 1s 4ms/step\n",
      "comm_round: 4 | global_acc: 90.619% | global_loss: 1.6333839893341064\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 5 | global_acc: 91.357% | global_loss: 1.6156213283538818\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 6 | global_acc: 91.714% | global_loss: 1.605328917503357\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 7 | global_acc: 92.238% | global_loss: 1.595242977142334\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 8 | global_acc: 92.429% | global_loss: 1.5894075632095337\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 9 | global_acc: 92.857% | global_loss: 1.5842498540878296\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 10 | global_acc: 93.167% | global_loss: 1.5791754722595215\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 11 | global_acc: 93.357% | global_loss: 1.5758095979690552\n",
      "132/132 [==============================] - 1s 5ms/step\n",
      "comm_round: 12 | global_acc: 93.667% | global_loss: 1.5732518434524536\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 13 | global_acc: 93.810% | global_loss: 1.570659875869751\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 14 | global_acc: 93.833% | global_loss: 1.5678318738937378\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 15 | global_acc: 93.929% | global_loss: 1.5660804510116577\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 16 | global_acc: 94.262% | global_loss: 1.5640450716018677\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 17 | global_acc: 94.357% | global_loss: 1.5622044801712036\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 18 | global_acc: 94.452% | global_loss: 1.5607378482818604\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 19 | global_acc: 94.524% | global_loss: 1.5592474937438965\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 20 | global_acc: 94.595% | global_loss: 1.5580480098724365\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 21 | global_acc: 94.857% | global_loss: 1.5568842887878418\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 22 | global_acc: 94.857% | global_loss: 1.555850625038147\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 23 | global_acc: 94.881% | global_loss: 1.5547525882720947\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 24 | global_acc: 94.929% | global_loss: 1.5536383390426636\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 25 | global_acc: 94.976% | global_loss: 1.5526854991912842\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 26 | global_acc: 94.976% | global_loss: 1.5520761013031006\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 27 | global_acc: 94.952% | global_loss: 1.5514497756958008\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 28 | global_acc: 95.119% | global_loss: 1.5507721900939941\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 29 | global_acc: 95.214% | global_loss: 1.5497945547103882\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 30 | global_acc: 95.190% | global_loss: 1.5489861965179443\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 31 | global_acc: 95.262% | global_loss: 1.547832727432251\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 32 | global_acc: 95.262% | global_loss: 1.547121524810791\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 33 | global_acc: 95.286% | global_loss: 1.5464760065078735\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 34 | global_acc: 95.286% | global_loss: 1.545838475227356\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 35 | global_acc: 95.214% | global_loss: 1.5449146032333374\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 36 | global_acc: 95.214% | global_loss: 1.5445349216461182\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 37 | global_acc: 95.286% | global_loss: 1.5437567234039307\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 38 | global_acc: 95.357% | global_loss: 1.5435996055603027\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 39 | global_acc: 95.429% | global_loss: 1.5429795980453491\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 40 | global_acc: 95.500% | global_loss: 1.5423654317855835\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 41 | global_acc: 95.524% | global_loss: 1.5419937372207642\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 42 | global_acc: 95.548% | global_loss: 1.5414597988128662\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 43 | global_acc: 95.571% | global_loss: 1.5410763025283813\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 44 | global_acc: 95.619% | global_loss: 1.540845274925232\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 45 | global_acc: 95.643% | global_loss: 1.5402978658676147\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 46 | global_acc: 95.595% | global_loss: 1.5396517515182495\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 47 | global_acc: 95.619% | global_loss: 1.5394154787063599\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 48 | global_acc: 95.690% | global_loss: 1.538784146308899\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 49 | global_acc: 95.643% | global_loss: 1.5384340286254883\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 50 | global_acc: 95.667% | global_loss: 1.5381035804748535\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 51 | global_acc: 95.738% | global_loss: 1.5375332832336426\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 52 | global_acc: 95.738% | global_loss: 1.537216305732727\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 53 | global_acc: 95.690% | global_loss: 1.5368015766143799\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 54 | global_acc: 95.738% | global_loss: 1.5365686416625977\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 55 | global_acc: 95.786% | global_loss: 1.5360740423202515\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 56 | global_acc: 95.690% | global_loss: 1.5360671281814575\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 57 | global_acc: 95.810% | global_loss: 1.5353906154632568\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 58 | global_acc: 95.833% | global_loss: 1.5349427461624146\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 59 | global_acc: 95.833% | global_loss: 1.5346938371658325\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 60 | global_acc: 95.857% | global_loss: 1.5344698429107666\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 61 | global_acc: 95.857% | global_loss: 1.5342817306518555\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 62 | global_acc: 95.952% | global_loss: 1.533766746520996\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 63 | global_acc: 95.929% | global_loss: 1.5334291458129883\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 64 | global_acc: 95.905% | global_loss: 1.5331357717514038\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 65 | global_acc: 95.976% | global_loss: 1.5329864025115967\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 66 | global_acc: 95.857% | global_loss: 1.532701849937439\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 67 | global_acc: 95.905% | global_loss: 1.532396912574768\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 68 | global_acc: 95.976% | global_loss: 1.5323374271392822\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 69 | global_acc: 96.071% | global_loss: 1.5318480730056763\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 70 | global_acc: 96.071% | global_loss: 1.5315922498703003\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 71 | global_acc: 96.071% | global_loss: 1.5315227508544922\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 72 | global_acc: 96.095% | global_loss: 1.5312941074371338\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 73 | global_acc: 96.095% | global_loss: 1.530981183052063\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 74 | global_acc: 96.095% | global_loss: 1.5307931900024414\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 75 | global_acc: 96.071% | global_loss: 1.5305339097976685\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 76 | global_acc: 96.095% | global_loss: 1.5303791761398315\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 77 | global_acc: 96.119% | global_loss: 1.5301513671875\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 78 | global_acc: 96.119% | global_loss: 1.530068278312683\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 79 | global_acc: 96.167% | global_loss: 1.5297572612762451\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 80 | global_acc: 96.143% | global_loss: 1.52950119972229\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 81 | global_acc: 96.167% | global_loss: 1.5293123722076416\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 82 | global_acc: 96.167% | global_loss: 1.529280424118042\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 83 | global_acc: 96.143% | global_loss: 1.5289883613586426\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 84 | global_acc: 96.167% | global_loss: 1.5288318395614624\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 85 | global_acc: 96.190% | global_loss: 1.5286109447479248\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 86 | global_acc: 96.214% | global_loss: 1.5283305644989014\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 87 | global_acc: 96.238% | global_loss: 1.5282005071640015\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 88 | global_acc: 96.238% | global_loss: 1.5281121730804443\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 89 | global_acc: 96.190% | global_loss: 1.5280871391296387\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 90 | global_acc: 96.238% | global_loss: 1.5277862548828125\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 91 | global_acc: 96.310% | global_loss: 1.5276892185211182\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 92 | global_acc: 96.310% | global_loss: 1.527374029159546\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 93 | global_acc: 96.262% | global_loss: 1.5272331237792969\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 94 | global_acc: 96.357% | global_loss: 1.527138352394104\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 95 | global_acc: 96.333% | global_loss: 1.5270086526870728\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 96 | global_acc: 96.333% | global_loss: 1.5268326997756958\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 97 | global_acc: 96.333% | global_loss: 1.5267877578735352\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 98 | global_acc: 96.333% | global_loss: 1.5266051292419434\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 99 | global_acc: 96.357% | global_loss: 1.5263930559158325\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 100 | global_acc: 96.357% | global_loss: 1.526344895362854\n"
     ]
    }
   ],
   "source": [
    "accuracies25 = fedML(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = accuracies25\n",
    "x_axis = []\n",
    "for i in range(100):\n",
    "    x_axis.append(i+1)\n",
    "plt.plot(x_axis, accuracies, color=\"blue\")\n",
    "plt.xlabel(\"Training round\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('output/acc25.csv', accuracies25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7c783bdd1001b55fab5c22007d050c844afa9d766f14df437f43c40fd2b4e70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
