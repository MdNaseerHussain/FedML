{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated ML\n",
    "## Contents\n",
    "1. Introduction\n",
    "1. Reading an image from the dataset\n",
    "1. Loading Images and Labels\n",
    "1. Splitting training and testing data\n",
    "1. Creating clients\n",
    "1. Creating helper nodes\n",
    "1. Batching clients' and test data\n",
    "1. Creating an MLP model\n",
    "1. Optimizer, Loss function and Metrics to compile the model\n",
    "1. Utility functions for the Federated Averaging\n",
    "1. Functions to fetch and set shape of model weights\n",
    "1. Modulation and Demodulation functions for Communication\n",
    "1. Transmission functions from Client to Helper and Helper to Master\n",
    "1. Model test function\n",
    "1. Federated Averaging Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we have implemented i working Federated ML model. The goal is to simulate packet losses in communication between the server and the clients in the Federated Averaging Algorithm. The function once implemented will be added to the algorithm near the TODO's in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "image = cv2.imread(\"datasets/numbers/trainingSet/0/img_1.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.title(\"Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processed 1/10\n",
      "[INFO] Processed 2/10\n",
      "[INFO] Processed 3/10\n",
      "[INFO] Processed 4/10\n",
      "[INFO] Processed 5/10\n",
      "[INFO] Processed 6/10\n",
      "[INFO] Processed 7/10\n",
      "[INFO] Processed 8/10\n",
      "[INFO] Processed 9/10\n",
      "[INFO] Processed 10/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "dir_path = \"datasets/numbers/trainingSet/\"\n",
    "images = list()\n",
    "labels = list()\n",
    "for number in range(0, 10):\n",
    "    folder = dir_path + str(number)\n",
    "    for image_file in os.listdir(folder):\n",
    "        image_gray = cv2.imread(os.path.join(folder, image_file), cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.array(image_gray).flatten()\n",
    "        images.append(image/255)\n",
    "        labels.append(number)\n",
    "    print(\"[INFO] Processed {}/{}\".format(number + 1, 10))\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num_clients = 16\n",
    "client_names = [\"client_{}\".format(i + 1) for i in range(num_clients)]\n",
    "data = list(zip(images, labels))\n",
    "random.shuffle(data)\n",
    "size = len(data)//num_clients\n",
    "data_shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "clients = {client_names[i]: data_shards[i] for i in range(num_clients)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating helper nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "num_helpers = math.ceil(math.log2(num_clients))\n",
    "error_links = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching clients' and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "batch_size = 32\n",
    "clients_batched = dict()\n",
    "for (client_name, data_shard) in clients.items():\n",
    "    data, labels = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(labels)))\n",
    "    clients_batched[client_name] = dataset.shuffle(len(labels)).batch(batch_size)\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((images_test, labels_test)).batch(len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Multi Layer Perception (MLP) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_shape=(shape,)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, Loss function and Metrics to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdnaj\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "lr = 0.01 \n",
    "comms_round = 100\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = SGD(lr=lr, decay=lr/comms_round, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions for the Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_scaling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    avg_grad = list()\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to fetch and set shape of model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(weights):\n",
    "    shapes = [i.shape for i in weights]\n",
    "    return shapes\n",
    "\n",
    "def flatten_model_weights(weights):\n",
    "    flattened_weights = np.concatenate([i.flatten() for i in weights])\n",
    "    return flattened_weights\n",
    "\n",
    "def restore_model_shape(flattened_weights, shapes):\n",
    "    weights = []\n",
    "    index = 0\n",
    "    for shape in shapes:\n",
    "        size = np.product(shape)\n",
    "        arr = np.array(flattened_weights[index : index + size])\n",
    "        weights.append(arr.reshape(shape))\n",
    "        index += size\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modulation and Demodulation Functions for Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import random\n",
    "\n",
    "def modulation(weights):\n",
    "    weights = flatten_model_weights(weights)\n",
    "    packets = []\n",
    "    for i in range(len(weights)):\n",
    "        packet = BitArray(float=weights[i], length=32)\n",
    "        packets.append(packet.bin)\n",
    "    return packets\n",
    "\n",
    "def demodulation(weights, model_shape):\n",
    "    return restore_model_shape(weights, model_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transmission functions from Client to Helper and Helper to Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_weights_list = []\n",
    "comm_matrix = []\n",
    "\n",
    "def masterReceiver(helpersData):\n",
    "    g1 = helpersData[0]\n",
    "    g2 = helpersData[1]\n",
    "    g3 = helpersData[2]\n",
    "    g4 = helpersData[3]\n",
    "    if g1 == 'X':\n",
    "        g1 = [0]*len(g2)\n",
    "        for i in range(len(g2)):\n",
    "            g1[i] = g4[i] - g2[i] - g3[i]\n",
    "    if g2 == 'X':\n",
    "        g2 = [0]*len(g1)\n",
    "        for i in range(len(g1)):\n",
    "            g2[i] = g4[i] - g1[i] - g3[i]\n",
    "    if g3 == 'X':\n",
    "        g3 = [0]*len(g4)\n",
    "        for i in range(len(g4)):\n",
    "            if i < len(g1):\n",
    "                g3[i] = g4[i] - g1[i] - g2[i]\n",
    "            else:\n",
    "                g3[i] = g4[i]\n",
    "    g = g1 + g2 + g3    \n",
    "    scaled_weights_list.append(g)\n",
    "\n",
    "def create_comm_matrix(num_clients, num_helpers):\n",
    "    scaled_weights_list.clear()\n",
    "    comm_matrix.clear()\n",
    "    for i in range(num_clients):\n",
    "        comm_matrix.append([])\n",
    "        for j in range(num_helpers):\n",
    "            comm_matrix[i].append(0)\n",
    "            comm_matrix[i][j] = 'XX'\n",
    "    return comm_matrix\n",
    "\n",
    "def transmissionCH(bitWeights, comm_matrix, client, packet_loss_prob):\n",
    "    g1 = bitWeights[:len(bitWeights)//3]\n",
    "    g2 = bitWeights[len(bitWeights)//3:2*len(bitWeights)//3]\n",
    "    g3 = bitWeights[2*len(bitWeights)//3:]\n",
    "    g4 = []\n",
    "    for i in range(len(g3)):\n",
    "        w1 = 0\n",
    "        if i < len(g1):\n",
    "            w1 = BitArray(bin=g1[i]).float\n",
    "        w2 = 0\n",
    "        if i < len(g2):\n",
    "            w2 = BitArray(bin=g2[i]).float\n",
    "        w3 = BitArray(bin=g3[i]).float\n",
    "        w4 = w1 + w2 + w3\n",
    "        g4.append(BitArray(float=w4, length=32).bin)\n",
    "    g1 = ''.join(g1)\n",
    "    g2 = ''.join(g2)\n",
    "    g3 = ''.join(g3)\n",
    "    g4 = ''.join(g4)\n",
    "    comm_matrix[client][0] = g1\n",
    "    comm_matrix[client][1] = g2\n",
    "    comm_matrix[client][2] = g3\n",
    "    comm_matrix[client][3] = g4\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][0] = 'X'*len(g1)\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][1] = 'X'*len(g2)\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][2] = 'X'*len(g3)\n",
    "    if random.random() < packet_loss_prob:\n",
    "        comm_matrix[client][3] = 'X'*len(g4)\n",
    "\n",
    "def transmissionHM(comm_matrix):\n",
    "    comm_links = {}\n",
    "    lost_clients = 0\n",
    "    for i in range(len(comm_matrix)):\n",
    "        mask = ''\n",
    "        for j in range(len(comm_matrix[i])):\n",
    "            if comm_matrix[i][j][0] != 'X':\n",
    "                mask += '1'\n",
    "            else:\n",
    "                mask += '0'\n",
    "        if mask in comm_links:\n",
    "            comm_links[mask].append(i)\n",
    "        else:\n",
    "            comm_links[mask] = [i]\n",
    "    for mask in comm_links:\n",
    "        summed_g1 = [0]*(len(comm_matrix[0][0])//32)\n",
    "        summed_g2 = [0]*(len(comm_matrix[0][1])//32)\n",
    "        summed_g3 = [0]*(len(comm_matrix[0][2])//32)\n",
    "        summed_g4 = [0]*(len(comm_matrix[0][3])//32)\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i] == '1':\n",
    "                for client in comm_links[mask]:\n",
    "                    if i == 0:\n",
    "                        g1 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g1[j//32] = BitArray(bin=comm_matrix[client][i][j:j+32]).float\n",
    "                        for j in range(len(g1)):\n",
    "                            summed_g1[j] += g1[j]\n",
    "                    elif i == 1:\n",
    "                        g2 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g2[j//32] = BitArray(bin=comm_matrix[client][i][j: j+32]).float\n",
    "                        for j in range(len(g2)):\n",
    "                            summed_g2[j] += g2[j]\n",
    "                    elif i == 2:\n",
    "                        g3 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g3[j//32] = BitArray(bin=comm_matrix[client][i][j: j+32]).float\n",
    "                        for j in range(len(g3)):\n",
    "                            summed_g3[j] += g3[j]\n",
    "                    else:\n",
    "                        g4 = [0]*(len(comm_matrix[client][i])//32)\n",
    "                        for j in range(0, len(comm_matrix[client][i]), 32):\n",
    "                            g4[j//32] = BitArray(bin=comm_matrix[client][i][j: j+32]).float\n",
    "                        for j in range(len(g4)):\n",
    "                            summed_g4[j] += g4[j]\n",
    "        X_cnt = 0\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i] == '0':\n",
    "                X_cnt += 1\n",
    "                if i == 0:\n",
    "                    summed_g1 = 'X'\n",
    "                elif i == 1:\n",
    "                    summed_g2 = 'X'\n",
    "                elif i == 2:\n",
    "                    summed_g3 = 'X'\n",
    "                else:\n",
    "                    summed_g4 = 'X'\n",
    "        if X_cnt > 1:\n",
    "            lost_clients += len(comm_links[mask])\n",
    "        else:\n",
    "            masterReceiver([summed_g1, summed_g2, summed_g3, summed_g4])\n",
    "    return [scaled_weights_list, lost_clients]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import CategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = CategoricalCrossentropy(from_logits=True)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round+1, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated Averaging Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def fedML(packet_loss_prob=0):\n",
    "    smlp_global = SimpleMLP()\n",
    "    global_model = smlp_global.build(784, 10)\n",
    "    model_shape = get_shape(global_model.get_weights())\n",
    "    accuracy = []\n",
    "    for comm_round in range(comms_round):\n",
    "        global_weights = global_model.get_weights()\n",
    "        client_names= list(clients_batched.keys())\n",
    "        comm_matrix = create_comm_matrix(num_clients, num_helpers)\n",
    "        random.shuffle(client_names)\n",
    "        for client_number, client in enumerate(client_names):\n",
    "            smlp_local = SimpleMLP()\n",
    "            local_model = smlp_local.build(784, 10)\n",
    "            local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "            local_model.set_weights(global_weights)\n",
    "            local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "            scaling_factor = weight_scaling_factor(clients_batched, client)\n",
    "            scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "            bitWeights = modulation(scaled_weights)\n",
    "            transmissionCH(bitWeights, comm_matrix, client_number, packet_loss_prob)\n",
    "            K.clear_session()\n",
    "        scaled_weights_list, lost_clients = transmissionHM(comm_matrix)\n",
    "        if lost_clients != 0:\n",
    "            compensated_lost_weights = scale_model_weights(global_weights, lost_clients*weight_scaling_factor(clients_batched, 'client_1'))\n",
    "            packets = modulation(compensated_lost_weights)\n",
    "            weights = packets\n",
    "            for i in range(len(packets)):\n",
    "                weights[i] = BitArray(bin=packets[i]).float\n",
    "            scaled_weights_list.append(weights)\n",
    "        global_weights = sum_scaled_weights(scaled_weights_list)\n",
    "        global_weights = demodulation(global_weights, model_shape)\n",
    "        global_model.set_weights(global_weights)\n",
    "        for(X_test, Y_test) in test_batched:\n",
    "            global_acc, _ = test_model(X_test, Y_test, global_model, comm_round)\n",
    "            accuracy.append(global_acc)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 1 | global_acc: 68.643% | global_loss: 2.1757850646972656\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 2 | global_acc: 73.095% | global_loss: 2.1444075107574463\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 3 | global_acc: 86.119% | global_loss: 1.8978887796401978\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 4 | global_acc: 86.786% | global_loss: 1.876223087310791\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 5 | global_acc: 87.667% | global_loss: 1.8081368207931519\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 6 | global_acc: 88.143% | global_loss: 1.7723041772842407\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 7 | global_acc: 88.786% | global_loss: 1.7148503065109253\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 8 | global_acc: 89.381% | global_loss: 1.6907098293304443\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 9 | global_acc: 89.929% | global_loss: 1.6646989583969116\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 10 | global_acc: 90.286% | global_loss: 1.6509795188903809\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 11 | global_acc: 90.667% | global_loss: 1.6417266130447388\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 12 | global_acc: 90.643% | global_loss: 1.6346286535263062\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 13 | global_acc: 91.024% | global_loss: 1.6280776262283325\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 14 | global_acc: 90.952% | global_loss: 1.6264325380325317\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 15 | global_acc: 91.024% | global_loss: 1.6226069927215576\n",
      "132/132 [==============================] - 1s 8ms/step\n",
      "comm_round: 16 | global_acc: 91.190% | global_loss: 1.6195217370986938\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 17 | global_acc: 91.286% | global_loss: 1.6167588233947754\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 18 | global_acc: 91.262% | global_loss: 1.6148988008499146\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 19 | global_acc: 91.405% | global_loss: 1.6118669509887695\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 20 | global_acc: 91.476% | global_loss: 1.6097809076309204\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 21 | global_acc: 91.548% | global_loss: 1.606863260269165\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 22 | global_acc: 91.643% | global_loss: 1.6049385070800781\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 23 | global_acc: 91.810% | global_loss: 1.602188229560852\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 24 | global_acc: 91.786% | global_loss: 1.6008179187774658\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 25 | global_acc: 91.952% | global_loss: 1.5998730659484863\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 26 | global_acc: 91.857% | global_loss: 1.5988043546676636\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "comm_round: 27 | global_acc: 92.000% | global_loss: 1.5979552268981934\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "comm_round: 28 | global_acc: 92.071% | global_loss: 1.5965989828109741\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 29 | global_acc: 92.071% | global_loss: 1.5956159830093384\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 30 | global_acc: 92.000% | global_loss: 1.5954118967056274\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 31 | global_acc: 92.238% | global_loss: 1.593538761138916\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 32 | global_acc: 92.214% | global_loss: 1.5920206308364868\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 33 | global_acc: 92.452% | global_loss: 1.5910193920135498\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 34 | global_acc: 92.524% | global_loss: 1.5900912284851074\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 35 | global_acc: 92.548% | global_loss: 1.589495062828064\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 36 | global_acc: 92.524% | global_loss: 1.5889856815338135\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 37 | global_acc: 92.595% | global_loss: 1.588046669960022\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 38 | global_acc: 92.571% | global_loss: 1.5873690843582153\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 39 | global_acc: 92.619% | global_loss: 1.586883544921875\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 40 | global_acc: 92.643% | global_loss: 1.5864994525909424\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 41 | global_acc: 92.738% | global_loss: 1.585971713066101\n",
      "132/132 [==============================] - 1s 11ms/step\n",
      "comm_round: 42 | global_acc: 92.738% | global_loss: 1.5854640007019043\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 43 | global_acc: 92.810% | global_loss: 1.5847758054733276\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 44 | global_acc: 92.881% | global_loss: 1.5841609239578247\n",
      "132/132 [==============================] - 1s 9ms/step\n",
      "comm_round: 45 | global_acc: 92.929% | global_loss: 1.5833544731140137\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 46 | global_acc: 93.048% | global_loss: 1.58274245262146\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 47 | global_acc: 93.000% | global_loss: 1.5823522806167603\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 48 | global_acc: 93.095% | global_loss: 1.5821924209594727\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 49 | global_acc: 93.119% | global_loss: 1.581676959991455\n",
      "132/132 [==============================] - 2s 16ms/step\n",
      "comm_round: 50 | global_acc: 93.071% | global_loss: 1.5816738605499268\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 51 | global_acc: 93.143% | global_loss: 1.5810576677322388\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 52 | global_acc: 93.095% | global_loss: 1.5807085037231445\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 53 | global_acc: 93.119% | global_loss: 1.5800083875656128\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 54 | global_acc: 93.190% | global_loss: 1.5793282985687256\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 55 | global_acc: 93.262% | global_loss: 1.5792713165283203\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 56 | global_acc: 93.286% | global_loss: 1.5784019231796265\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 57 | global_acc: 93.333% | global_loss: 1.5780408382415771\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 58 | global_acc: 93.310% | global_loss: 1.5779248476028442\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 59 | global_acc: 93.310% | global_loss: 1.5776500701904297\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 60 | global_acc: 93.286% | global_loss: 1.5773651599884033\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 61 | global_acc: 93.238% | global_loss: 1.57700777053833\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 62 | global_acc: 93.381% | global_loss: 1.5766880512237549\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 63 | global_acc: 93.357% | global_loss: 1.5764813423156738\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 64 | global_acc: 93.310% | global_loss: 1.575849175453186\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 65 | global_acc: 93.524% | global_loss: 1.5756889581680298\n",
      "132/132 [==============================] - 2s 16ms/step\n",
      "comm_round: 66 | global_acc: 93.452% | global_loss: 1.5751593112945557\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 67 | global_acc: 93.452% | global_loss: 1.5750434398651123\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 68 | global_acc: 93.524% | global_loss: 1.5751879215240479\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "comm_round: 69 | global_acc: 93.524% | global_loss: 1.5743924379348755\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 70 | global_acc: 93.548% | global_loss: 1.5740387439727783\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 71 | global_acc: 93.643% | global_loss: 1.5737038850784302\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 72 | global_acc: 93.595% | global_loss: 1.5733510255813599\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 73 | global_acc: 93.595% | global_loss: 1.5731078386306763\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 74 | global_acc: 93.643% | global_loss: 1.5730229616165161\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 75 | global_acc: 93.690% | global_loss: 1.5727978944778442\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 76 | global_acc: 93.619% | global_loss: 1.5726730823516846\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 77 | global_acc: 93.667% | global_loss: 1.5724388360977173\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 78 | global_acc: 93.738% | global_loss: 1.5720824003219604\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 79 | global_acc: 93.738% | global_loss: 1.5718199014663696\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 80 | global_acc: 93.738% | global_loss: 1.5714962482452393\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 81 | global_acc: 93.619% | global_loss: 1.5710182189941406\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 82 | global_acc: 93.619% | global_loss: 1.570937991142273\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 83 | global_acc: 93.619% | global_loss: 1.5706368684768677\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "comm_round: 84 | global_acc: 93.690% | global_loss: 1.570616364479065\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 85 | global_acc: 93.714% | global_loss: 1.5705994367599487\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 86 | global_acc: 93.738% | global_loss: 1.570391297340393\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 87 | global_acc: 93.690% | global_loss: 1.5700067281723022\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 88 | global_acc: 93.738% | global_loss: 1.5696790218353271\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 89 | global_acc: 93.738% | global_loss: 1.5696338415145874\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 90 | global_acc: 93.762% | global_loss: 1.569458246231079\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 91 | global_acc: 93.738% | global_loss: 1.5692058801651\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 92 | global_acc: 93.762% | global_loss: 1.5690274238586426\n",
      "132/132 [==============================] - 2s 12ms/step\n",
      "comm_round: 93 | global_acc: 93.690% | global_loss: 1.5690773725509644\n",
      "132/132 [==============================] - 2s 15ms/step\n",
      "comm_round: 94 | global_acc: 93.667% | global_loss: 1.5690898895263672\n",
      "132/132 [==============================] - 2s 14ms/step\n",
      "comm_round: 95 | global_acc: 93.738% | global_loss: 1.568887710571289\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 96 | global_acc: 93.833% | global_loss: 1.5683625936508179\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 97 | global_acc: 93.857% | global_loss: 1.5682979822158813\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 98 | global_acc: 93.857% | global_loss: 1.568184494972229\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 99 | global_acc: 93.976% | global_loss: 1.5680941343307495\n",
      "132/132 [==============================] - 2s 13ms/step\n",
      "comm_round: 100 | global_acc: 94.048% | global_loss: 1.5678764581680298\n"
     ]
    }
   ],
   "source": [
    "accuracies50 = fedML(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = accuracies50\n",
    "x_axis = []\n",
    "for i in range(100):\n",
    "    x_axis.append(i+1)\n",
    "plt.plot(x_axis, accuracies, color=\"blue\")\n",
    "plt.xlabel(\"Training round\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('output/acc50.csv', accuracies50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7c783bdd1001b55fab5c22007d050c844afa9d766f14df437f43c40fd2b4e70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
